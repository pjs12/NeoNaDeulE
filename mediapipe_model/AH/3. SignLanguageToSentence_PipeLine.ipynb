{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ba63a7",
   "metadata": {},
   "source": [
    "### 동적수화 번역 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e617fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "\n",
    "def meadia_pipe(model, actions):\n",
    "    seq_length = 30\n",
    "\n",
    "    Text = [''] # 모션 텍스트\n",
    "    \n",
    "    # MediaPipe hands model\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    hands = mp_hands.Hands(\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    seq = []\n",
    "    action_seq = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, img = cap.read()\n",
    "        img0 = img.copy()\n",
    "\n",
    "        img = cv2.flip(img, 1)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if result.multi_hand_landmarks is not None:\n",
    "            hand_arr = []\n",
    "            for res in result.multi_hand_landmarks:\n",
    "                joint = np.zeros((21, 4))\n",
    "                for j, lm in enumerate(res.landmark):\n",
    "                    joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "\n",
    "                # Compute angles between joints\n",
    "                v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3] # Parent joint\n",
    "                v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3] # Child joint\n",
    "                v = v2 - v1 # [20, 3]\n",
    "                # Normalize v\n",
    "                v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "                # Get angle using arcos of dot product\n",
    "                angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                    v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                    v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "\n",
    "                angle = np.degrees(angle) # Convert radian to degree\n",
    "\n",
    "                d = np.concatenate([joint.flatten(), angle])\n",
    "                hand_arr.extend(d)\n",
    "\n",
    "                mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            if len(hand_arr) == 99:\n",
    "                    hand_arr.extend(np.zeros(99))\n",
    "\n",
    "            if len(hand_arr) > 198:\n",
    "                continue\n",
    "\n",
    "            seq.append(hand_arr)\n",
    "\n",
    "            if len(seq) < seq_length:\n",
    "                continue\n",
    "\n",
    "            input_data = np.expand_dims(np.array(seq[-seq_length:], dtype=np.float32), axis=0)\n",
    "            y_pred = model.predict(input_data).squeeze()\n",
    "            i_pred = int(np.argmax(y_pred))\n",
    "            conf = y_pred[i_pred]\n",
    "            if conf < 0.9:\n",
    "                continue\n",
    "\n",
    "            #print(i_pred)\n",
    "            action = actions[i_pred]\n",
    "            action_seq.append(action)\n",
    "            if len(action_seq) < 3:\n",
    "                continue\n",
    "            this_action = '?'\n",
    "            if action_seq[-1] == action_seq[-2] == action_seq[-3]:\n",
    "                this_action = action\n",
    "            font = ImageFont.truetype(\"fonts/gulim.ttc\", 20)\n",
    "            img = Image.fromarray(img)\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            draw.text((30,50), this_action, font=font, fill=(0,0,255))\n",
    "            img = np.array(img)\n",
    "\n",
    "            if Text[-1] != this_action :\n",
    "                Text.append(this_action)\n",
    "\n",
    "        # out.write(img0)\n",
    "        # out2.write(img)\n",
    "        cv2.imshow('img', img)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            cap.release()\n",
    "            \n",
    "            return Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d89ff",
   "metadata": {},
   "source": [
    "### 단어to문장 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9f83e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from tensorflow import keras\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)     \n",
    "\n",
    "def predict_mo(lst):\n",
    "    \n",
    "    reconstructed_model = keras.models.load_model(\"WTS_model.h5\")\n",
    "    char_indices = json.load(open(\"char_indices.json\",\"r\"))\n",
    "    indices_char = json.load(open(\"indices_char.json\",\"r\"))   \n",
    "    \n",
    "    result =''\n",
    "    \n",
    "    for i in lst:\n",
    "        if i[-1] == '요' or i[-1] == '다':\n",
    "            result += i + ' '\n",
    "            continue\n",
    "            \n",
    "        x = np.zeros((1, 5, len(char_indices)))\n",
    "        x[0, len(i), char_indices[i]] = 1.\n",
    "\n",
    "        preds = reconstructed_model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = indices_char[str(next_index)]\n",
    "        \n",
    "        \n",
    "        #y = josa_fuc(i, next_char)\n",
    "        result += (i + next_char + ' ')\n",
    "        \n",
    "    return result\n",
    "\n",
    "def new_text(text):\n",
    "    try:\n",
    "        text.remove('')\n",
    "        while '?' in text:\n",
    "            text.remove('?')\n",
    "    except:\n",
    "        return text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7316f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_words = ['', '?', '오늘', '?', '날씨', '?', '맑다']\n",
    "\n",
    "# np_words2 = new_text(mp_words)\n",
    "# print(np_words2)\n",
    "\n",
    "# sentence1 = predict_mo(np_words2)\n",
    "# print(sentence1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd892ec",
   "metadata": {},
   "source": [
    "### 파이프라인 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddd2a942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘은 날씨가 맑다 \n"
     ]
    }
   ],
   "source": [
    "actions1 = [\n",
    "    '오늘',\n",
    "    '날씨',\n",
    "    '맑다',\n",
    "]\n",
    "model1 = keras.models.load_model(\"mediapipe_model.h5\")\n",
    "\n",
    "mp_words = meadia_pipe(model1, actions1)\n",
    "    \n",
    "#print(mp_words) \n",
    "np_words2 = new_text(mp_words)\n",
    "#print(np_words2)\n",
    "\n",
    "sentence1 = predict_mo(np_words2)\n",
    "print(sentence1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c79ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
